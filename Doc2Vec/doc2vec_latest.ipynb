{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf6d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import logging\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac49bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "540292fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca31045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the words to remove\n",
    "words_to_remove = [\"References\", \"External links\", \"Galleries\", \"plant\", \"plants\", \"crop\", \"crops\", \"Wikimedia\", \"Wikispecies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42cd79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_First_1000.xlsx',\n",
    "              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Second_1000.xlsx',\n",
    "             'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Third_1000.xlsx']\n",
    "#              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Fourth_3001-6000_First_500.xlsx',\n",
    "#               'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Fourth_3001-6000_Second_500.xlsx',\n",
    "#               'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Fourth_3001-6000_Third_500.xlsx',\n",
    "#               'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Fourth_3001-6000_Fourth_500.xlsx',\n",
    "#               'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Fourth_3001-6000_Fifth_1000.xlsx',\n",
    "#              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Fifth_1000.xlsx',\n",
    "#              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Sixth_1000.xlsx',\n",
    "#              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Seventh_1000.xlsx',\n",
    "#              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Eighth_1000.xlsx',\n",
    "#              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Ninth_1000.xlsx',\n",
    "#              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Tenth_1000.xlsx',\n",
    "#              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Eleventh_2000.xlsx',\n",
    "#              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Twelveth_2000.xlsx',\n",
    "#              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Thirteenth_2000.xlsx',\n",
    "#              'C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Fourteenth_2000.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b6104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_paths = ['C:/Users/USER/Downloads/Agrifood System - Copy.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2745e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4524c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() #reduce a word to its base or dictionary form ( eg running to run or better to good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86478205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove references, external links, and galleries\n",
    "    for word in words_to_remove:\n",
    "        text = text.replace(word, '')\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, numbers, and non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize and remove stopwords, short words, and perform lemmatization\n",
    "    tokens = gensim.utils.simple_preprocess(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 1]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c79ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus_from_excel(file_path, tokens_only=False):\n",
    "    # Read data\n",
    "    data = pd.read_excel(file_path)\n",
    "\n",
    "    # Create an empty set to keep track of seen content\n",
    "    seen_content = set()\n",
    "\n",
    "    # Iterate through the rows in the 'Content' column\n",
    "    for i, item in enumerate(data['Content']):\n",
    "        # Check if the item is not NaN and contains non-empty cells\n",
    "        if pd.notna(item) and item.strip():\n",
    "            # Convert the item to a string\n",
    "            line = str(item)\n",
    "\n",
    "            # Check if the content has been seen before\n",
    "            if line not in seen_content:\n",
    "                # If not seen, add it to the set to avoid duplicates\n",
    "                seen_content.add(line)\n",
    "\n",
    "                # Tokenize the content\n",
    "                tokens = gensim.utils.simple_preprocess(line)\n",
    "\n",
    "                if tokens_only:\n",
    "                    # If tokens_only is True, yield only the tokens\n",
    "                    yield tokens\n",
    "                else:\n",
    "                    # If tokens_only is False, create a unique tag for the document\n",
    "                    # by combining the file path and document index\n",
    "                    tag = str(file_path) + '-' + str(i)\n",
    "\n",
    "                    # Yield a TaggedDocument, which pairs the tokens with a tag\n",
    "                    yield gensim.models.doc2vec.TaggedDocument(tokens, [tag])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3d4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = [] #This list will be used to store the documents or text data that will be processed and used to train the Doc2Vec model\n",
    "for file_path in file_paths:\n",
    "    train_corpus.extend(list(read_corpus_from_excel(file_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa53504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 10:48:42,482 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec(dm/m,d100,n5,w5,mc2,s0.001,t3)', 'datetime': '2023-11-15T10:48:42.482586', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "021f4994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 10:48:42,693 : INFO : collecting all words and their counts\n",
      "2023-11-15 10:48:42,695 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2023-11-15 10:48:42,931 : INFO : collected 60062 word types and 2236 unique tags from a corpus of 2236 examples and 1159683 words\n",
      "2023-11-15 10:48:42,931 : INFO : Creating a fresh vocabulary\n",
      "2023-11-15 10:48:43,047 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 32052 unique words (53.36485631514102%% of original 60062, drops 28010)', 'datetime': '2023-11-15T10:48:43.047325', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-11-15 10:48:43,047 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 1131673 word corpus (97.58468478023735%% of original 1159683, drops 28010)', 'datetime': '2023-11-15T10:48:43.047325', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-11-15 10:48:43,212 : INFO : deleting the raw counts dictionary of 60062 items\n",
      "2023-11-15 10:48:43,212 : INFO : sample=0.001 downsamples 33 most-common words\n",
      "2023-11-15 10:48:43,212 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 900502.3237872464 word corpus (79.6%% of prior 1131673)', 'datetime': '2023-11-15T10:48:43.212669', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-11-15 10:48:43,492 : INFO : estimated required memory for 32052 words and 100 dimensions: 43009200 bytes\n",
      "2023-11-15 10:48:43,494 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(train_corpus) #build the vocabulary for a Doc2Vec model based on the provided training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a92a75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'rice' appeared 172 times in the training corpus.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word 'rice' appeared {model.wv.get_vecattr('rice', 'count')} times in the training corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "521c0029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 10:48:43,531 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 32052 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-11-15T10:48:43.531855', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-11-15 10:48:44,552 : INFO : EPOCH 1 - PROGRESS: at 96.24% examples, 849485 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-15 10:48:44,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-15 10:48:44,588 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-15 10:48:44,599 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-15 10:48:44,600 : INFO : EPOCH - 1 : training on 1159683 raw words (902968 effective words) took 1.1s, 851357 effective words/s\n",
      "2023-11-15 10:48:45,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-15 10:48:45,591 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-15 10:48:45,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-15 10:48:45,601 : INFO : EPOCH - 2 : training on 1159683 raw words (902902 effective words) took 1.0s, 904904 effective words/s\n",
      "2023-11-15 10:48:46,620 : INFO : EPOCH 3 - PROGRESS: at 87.88% examples, 773041 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-15 10:48:46,742 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-15 10:48:46,745 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-15 10:48:46,752 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-15 10:48:46,753 : INFO : EPOCH - 3 : training on 1159683 raw words (902836 effective words) took 1.1s, 786232 effective words/s\n",
      "2023-11-15 10:48:47,764 : INFO : EPOCH 4 - PROGRESS: at 98.43% examples, 884526 words/s, in_qsize 2, out_qsize 1\n",
      "2023-11-15 10:48:47,765 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-15 10:48:47,767 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-15 10:48:47,777 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-15 10:48:47,777 : INFO : EPOCH - 4 : training on 1159683 raw words (902977 effective words) took 1.0s, 885320 effective words/s\n",
      "2023-11-15 10:48:48,789 : INFO : EPOCH 5 - PROGRESS: at 90.52% examples, 804394 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-15 10:48:48,875 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-15 10:48:48,875 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-15 10:48:48,881 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-15 10:48:48,888 : INFO : EPOCH - 5 : training on 1159683 raw words (902643 effective words) took 1.1s, 815356 effective words/s\n",
      "2023-11-15 10:48:49,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-15 10:48:49,887 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-15 10:48:49,898 : INFO : EPOCH 6 - PROGRESS: at 100.00% examples, 896533 words/s, in_qsize 0, out_qsize 1\n",
      "2023-11-15 10:48:49,900 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-15 10:48:49,900 : INFO : EPOCH - 6 : training on 1159683 raw words (902920 effective words) took 1.0s, 894473 effective words/s\n",
      "2023-11-15 10:48:50,905 : INFO : EPOCH 7 - PROGRESS: at 95.26% examples, 851563 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-15 10:48:50,951 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-15 10:48:50,953 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-15 10:48:50,968 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-15 10:48:50,969 : INFO : EPOCH - 7 : training on 1159683 raw words (902521 effective words) took 1.1s, 848684 effective words/s\n",
      "2023-11-15 10:48:51,974 : INFO : EPOCH 8 - PROGRESS: at 98.03% examples, 876991 words/s, in_qsize 3, out_qsize 0\n",
      "2023-11-15 10:48:51,994 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-15 10:48:51,997 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-15 10:48:52,003 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-15 10:48:52,003 : INFO : EPOCH - 8 : training on 1159683 raw words (902363 effective words) took 1.0s, 874912 effective words/s\n",
      "2023-11-15 10:48:53,007 : INFO : EPOCH 9 - PROGRESS: at 96.24% examples, 859070 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-15 10:48:53,036 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-15 10:48:53,036 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-15 10:48:53,036 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-15 10:48:53,036 : INFO : EPOCH - 9 : training on 1159683 raw words (902552 effective words) took 1.0s, 867469 effective words/s\n",
      "2023-11-15 10:48:54,053 : INFO : EPOCH 10 - PROGRESS: at 98.03% examples, 873095 words/s, in_qsize 3, out_qsize 0\n",
      "2023-11-15 10:48:54,072 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-11-15 10:48:54,072 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-11-15 10:48:54,085 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-11-15 10:48:54,085 : INFO : EPOCH - 10 : training on 1159683 raw words (903143 effective words) took 1.0s, 873982 effective words/s\n",
      "2023-11-15 10:48:54,088 : INFO : Doc2Vec lifecycle event {'msg': 'training on 11596830 raw words (9027825 effective words) took 10.6s, 855671 effective words/s', 'datetime': '2023-11-15T10:48:54.088037', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6a0bd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0257604   0.01848064  0.00999208 -0.02328071 -0.00672734 -0.04123252\n",
      "  0.0500344   0.03372451 -0.00288891 -0.01007057 -0.0067927  -0.01307904\n",
      "  0.03552444  0.00578831  0.00870091 -0.03514152  0.04326287 -0.0025482\n",
      " -0.0058521  -0.06088119 -0.00902999  0.00983492 -0.05473233 -0.00046851\n",
      "  0.00362012  0.02439969 -0.07253241  0.01170101  0.01202417 -0.02232227\n",
      "  0.02386621 -0.02044021 -0.0171322   0.01971511  0.02492699  0.04119387\n",
      "  0.04080671 -0.03070465 -0.02930884 -0.03181521  0.01328057 -0.05948669\n",
      " -0.02142613 -0.00641596 -0.01850217 -0.03005423 -0.0051272  -0.01908077\n",
      "  0.01309885  0.01654437 -0.02684827 -0.03099038 -0.02748269 -0.0395469\n",
      " -0.03330617 -0.02476671 -0.03020239 -0.00429308 -0.01266488 -0.0037087\n",
      " -0.01994755 -0.03861113  0.03821676  0.02578732  0.0069153   0.02916013\n",
      " -0.00027237 -0.00118128 -0.00530585  0.05347286  0.00325842  0.01221904\n",
      " -0.00853222  0.00969818  0.04003515 -0.0192888  -0.02499124 -0.02300078\n",
      " -0.02936913 -0.01565136  0.01217097 -0.0078511  -0.02652354  0.01563001\n",
      " -0.0215169   0.01340394 -0.02580946 -0.02196798 -0.01615216 -0.00152406\n",
      "  0.03434058 -0.0340235   0.01541743 -0.00152524 -0.01280139 -0.02172636\n",
      "  0.01208855 -0.04498958 -0.01550769 -0.01794668]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['rice', 'is', 'good']) #vector representation of the semantic content (significance of a piece of text)\n",
    "#numerical representation of the meaning of the new document\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cdf1e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the corpus: 2236\n"
     ]
    }
   ],
   "source": [
    "n_train_docs = len(train_corpus)\n",
    "print(\"Number of documents in the corpus:\", n_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5514540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similar_documents(doc_id, sims):\n",
    "    # Print the top 5 most similar documents with their similarity scores\n",
    "    print(\"SIMILAR DOCS PER MODEL:\\n\")\n",
    "    for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('THIRD-MOST', 2), ('FOURTH-MOST', 3), ('FIFTH-MOST', 4)]:\n",
    "        # Splits the document tag (a unique identifier) of the similar document to extract the file path and document index\n",
    "        #Checks if the tag has two parts (file path and index) to ensure it's a valid tag\n",
    "        #Extracts the file path, document index, and similarity score from the tag and similarity score pair\n",
    "        tag_parts = sims[index][0].split('-')\n",
    "        if len(tag_parts) == 2:\n",
    "            file_path = tag_parts[0]\n",
    "            doc_index = int(tag_parts[1])\n",
    "            similarity_score = sims[index][1]\n",
    "            doc_words = ' '.join(train_corpus[doc_index].words)\n",
    "            print(f'{label} ({similarity_score:.2f}): Document at index {doc_index} in file {file_path}\\n{doc_words}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d480855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMILAR DOCS PER MODEL:\n",
      "\n",
      "MOST (0.93): Document at index 1 in file C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_First_1000.xlsx\n",
      "abelmoschus manihot commonly known as aibika is flowering plant in the family malvaceae it was previously classified as species of hibiscus but is now categorized under the genus abelmoschus this plant is also referred to as the sunset muskmallow sunset hibiscus or hibiscus manihot growth habit although technically shrub aibika is perennial plant that under favorable conditions can grow over three meters in height it is easily propagated through cuttings and relatively disease resistant as result it is widely cultivated and often found along garden borders or as an intercrop in traditional tropical gardens its growth habit along with its nutritional value contributes to its popularity in home gardening and horticulture nutrition aibika is renowned for its highly nutritious properties its leaves are rich in essential vitamins including high content of vitamins and as well as iron moreover they contain approximately protein by dry weight making aibika valuable dietary source the leaves are commonly incorporated into various dishes such as tinola sinigang pinangat or used in salads in regions like the philippines applications apart from its culinary uses aibika has additional applications in different cultures in japan it is known as tororo aoi and is utilized to produce neri starchy substance used in traditional japanese papermaking washi similarly in korean it is referred to as hwang chok kyu and plays role in making dak pul an ingredient used in the production of hanji korean paper chemical constituents chromatographic and spectroscopic analysis published in china journal of chinese materia medica revealed the presence of thirteen compounds in aibika these compounds include myricetin cannabiscitrin myricetin beta glucopyranoside dihydroxy benzoic acid guanosine adenosine maleic acid acid triacontanol tetracosane sitosterol and beta sitosterol beta glucoside references external links abelmoschus manihot medic medicinal plant images database school of chinese medicine hong kong baptist university in chinese in english\n",
      "\n",
      "SECOND-MOST (0.85): Document at index 654 in file C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_First_1000.xlsx\n",
      "anisoptera thurifera is tree species in the family this asian species has been recorded from bangladesh through to new guinea the iucn has categorised it as vulnerable subspecies the catalogue of life lists two subspecies anisoptera thurifera polyandra anisoptera thurifera thurifera references\n",
      "\n",
      "THIRD-MOST (0.83): Document at index 678 in file C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_Second_1000.xlsx\n",
      "chervil anthriscus cerefolium sometimes called french parsley or garden chervil to distinguish it from similar plants also called chervil is delicate annual herb related to parsley it was formerly called myrhis due to its volatile oil with an aroma similar to the resinous substance myrrh it is commonly used to season mild flavoured dishes and is constituent of the french herb mixture fines herbes name the name chervil is from anglo norman from latin chaerephylla or choerephyllum meaning leaves of joy the latin is formed as from an ancient greek word χαιρέφυλλον chairephyllon biology member of the apiaceae chervil is native to the caucasus but was spread by the romans through most of europe where it is now naturalised it is also grown frequently in the united states where it sometimes escapes cultivation such escape can be recognized however as garden chervil is distinguished from all other anthriscus species growing in north america caucalis and sylvestris by its having lanceolate linear bracteoles and fruit with relatively long beak the plants grow to cm in with tripinnate leaves that may be curly the small white flowers form small umbels cm in across the fruit is about cm long oblong ovoid with slender ridged beak uses and impact culinary arts chervil is used particularly in france to season poultry seafood young spring vegetables such as carrots soups and sauces more delicate than parsley it has faint taste of liquorice or aniseed chervil is one of the four traditional french fines herbes along with tarragon chives and parsley which are essential to french cooking unlike the more pungent robust herbs such as thyme and rosemary which can take prolonged cooking the fines herbes are added at the last minute to salads omelettes and soups chemistry essential oil obtained via water distillation of wild turkish anthriscus cerefolium was analyzed by gas chromatography mass spectrometry identifying compounds methyl chavicol allyl undecane and pinene horticulture according to some slugs are attracted to chervil and the plant is sometimes used to bait them health chervil has had various uses in folk medicine it was claimed to be useful as digestive aid for lowering high blood pressure and infused with vinegar for curing hiccups besides its digestive properties it is used as mild stimulant chervil has also been implicated in strimmer dermatitis another name for due to spray from weed trimmers and similar forms of contact other plants in the family apiaceae can have similar effects cultivation transplanting chervil can be difficult due to the long taproot it prefers cool and moist location otherwise it rapidly goes to seed also known as bolting it is usually grown as cool season crop like lettuce and should be planted in early spring and late fall or in winter greenhouse regular harvesting of leaves also helps to prevent bolting if plants bolt despite precautions the plant can be periodically re sown throughout the growing season thus producing fresh plants as older plants bolt and go out of production chervil grows to height of to inches to cm and width of to inches to cm references further reading howard michael traditional folk remedies century philosoph hadas jacob meir aharoni june mode of action of co in delaying senescence of chervil leaves acta horticulturae doi actahortic el gendy el gohary omer hendawy hussein petrova stancheva july effect of nitrogen and potassium fertilizer on herbage and oil yield of chervil plant anthriscus cerefolium industrial crops and products doi indcrop liopa tsakalidi barouchas salinity chitin and ga effects on seed germination of chervil anthriscus cerefolium australian journal of crop science simándi oszagyán lemberkovics petri kéry fejes sz may comparison of the volatile composition of chervil oil obtained by and supercritical fluid extraction journal of essential oil research doi\n",
      "\n",
      "FOURTH-MOST (0.83): Document at index 796 in file C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_First_1000.xlsx\n",
      "aristotelia serrata commonly known as wineberry or in the māori language makomako or just mako is small tree in the family elaeocarpaceae in the genus aristotelia found in the north island south island and stewart island of new zealand description aristotelia serrata also known as wineberry is small deciduous fast growing tree or shrub the tree can reach up to tall with trunk diameter up to cm the bark is pale brown smooth and patterned with flat lenticels branches are long slender and spreading branchlets have reddish brown color when pubescent leaves aristotelia serrata leaves have distinguishable traits leaves are thin deeply and sharply serrated light or dark green on adaxial surface often pinkish green on abaxial surface veins distinct on both surfaces size between cm the leaves are disposed in opposite or subopposite pairs they have drawn out pointed tips and prominent veins forming an obvious net like vein pattern on both sides the margins are strikingly toothed with larger narrowly pointed irregular jagged teeth bearing smaller teeth some trees have red purple twigs and leaf undersides others are just green the leaves have long stalks and each leaf stalk has pair of small narrow stipules sometimes few teeth at its base in the axils of the leafstalks are pointed buds which can grow out into leafy shots or inflorescences flowers flowers occur in an inflorescence of numerous cymes flowers of all shades intermixed coloured in cream through pink to dark red flowers has to mm diam petals lobed stigma with lobes stamens numerous arising from glandular disc flower has cm long on slender pubescent pedicels with around mm long flowers have ovate sepals around mm long petals lobed often deeply mm long stamens occur on glandular disk minutely pubescent ovary celled styles the flowers are very numerous in much branched clusters they have petals with rounded incised lobes at the ends and look like small versions of elaeocarpus flowers they are almost colourless when they open then they change to pink red and dark red providing colorful display wineberry has male and female flowers on different plants with some bisexual flowers among the males female flowers are borne in large panicles on short shoots just above leaves or old leaf scars on year old wood of the upper leafy branchlets fruits the fruit is berry that is mm in diameter black containing angular seeds with locules and axile placentation they are red through dark red to almost black distribution new zealand range endemic to new zealand wineberry is found throughout the south island of new zealand and lower north island it is common in moist forest and scrub land within the lowland montane and subalpine climates wineberry can also be found on stewart island habitat preferences taking advantage of ecological disturbances such as natural tree falls serrata is plentiful in regenerating forest and damp river margins forest clearings which are followed by the colonization of wineberry are often due to land slip storm damage natural tree fall forest clearings and forest fire life cycle phenology wineberry is quick growing deciduous tree gradually losing leaves during the winter it may become fully bare prior to new leaves and flower development in spring wineberry is an attractive tree with pinkish foliage and rose coloured flowers in the spring berries ripen in the summer as the flowers of the wineberry mature they turn from white to red there are both female and male flowers on different plants with some bisexual flowers among the males predators parasites and diseases wineberry acts as host to numerous associated plant species and is fed on by native birds and insects associated plants include range of mosses to herbaceous plants such as orthotrichum cyathiforme orthotrichum calvum macroacoma tenue leptophyllopsis laxa and lleostylus micranthus the berries of serrata are susceptible to frugivory by both birds and mammals kererū are known to feed on the fruit of wineberry in order to conserve kererū populations it is suggested by the department of conservation that wineberry be planted as food source the berries of the wineberry are not the only parts eaten kawakawa looper cleora scriptaria larvae can be found feeding on its leaves cultural uses aristotelia serrata has multitude of uses by both european settlers and māori māori used makomako medicinally by boiling its leaves as an application to burns and infected wounds the berries serve as food and are often eaten by children and can be squeezed to make thick sweet drink wineberry can be used in variety of way to create dyes the plant contains tannins and the bark can provide blue black dye european settlers burnt the shoots of the wineberry changing the wood to charcoal for the production of gunpowder interesting facts ecology often form thickets after felling of forest nomenclature aristotelia means after aristotle the greek philosopher systematic botany there may exist two varieties for the same species one with light green leaves and bright red fruits and the other with dark green leaves purplish below and dark fruits references external links map showing citizen scientist observations from naturewatchnz\n",
      "\n",
      "FIFTH-MOST (0.82): Document at index 659 in file C:/Users/USER/Final Scraped/wiki_scraped_FPIDatabase_RA_First_1000.xlsx\n",
      "annona is species of plant in the family annonaceae it is native to el salvador guatemala honduras and mexico john donnell smith the american botanist who first formally described the species named it after its large leaves latinized forms of greek μακρός makrós and φύλλον phúllon description bush reaching meters in height its membranous elliptical leaves are by centimeters and have rounded or slightly indented tips the leaves are hairless on both surfaces its petioles are millimeters long its solitary flowers are on centimeter long pedicels its oval sepals are millimeters long and covered in rust colored shaggy hairs its outer petals are by millimeters and covered in fine hairs the mature thick fleshy outer petals have an outer surface that is green at the base and yellow at the tip while its inner surface has pink and red highlights its inner petals are rudimentary its ovaries are hairless reproductive biology the pollen of is shed as permanent tetrads distribution and habitat it has been observed growing at an elevation of meters uses bioactive molecules extracted from the leaves have been reported to have alpha glucosidase inhibitor activity references external links annona donn sm at the global biodiversity information facility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 1 \n",
    "inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "sims = model.dv.most_similar([inferred_vector], topn=n_train_docs)\n",
    "print_similar_documents(doc_id, sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949f31dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
